{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "oT5s_vrR70Fm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT5s_vrR70Fm",
        "outputId": "90bb80ea-1c60-4766-90a5-d77fea952779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BIdMXNUQfORw",
      "metadata": {
        "id": "BIdMXNUQfORw"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook demonstrates how to build a chatbot that answers questions about Nestlé's HR policies. It’s powered by OpenAI’s GPT model to understand and respond to queries in natural language, and it uses Gradio to create a clean, easy-to-use interface. The system extracts information from PDF documents, converts it into vector form, and enables intelligent question-answering.\n",
        "\n",
        "### Project Overview\n",
        "The aim is to assist Nestlé’s HR team by automating responses to queries about HR reports. This involves processing PDF data, generating vector embeddings, and setting up a retrieval-based QA system with a simple and interactive chatbot interface.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CpLi5gpQALdx",
      "metadata": {
        "id": "CpLi5gpQALdx"
      },
      "source": [
        "## Installing Dependencies\n",
        "\n",
        "We will install all the necessary Python packages required for the project:\n",
        "\n",
        "-   `langchain`: A framework for developing applications powered by language models.\n",
        "-   `openai`: The official OpenAI library for working with models like GPT-3.5 Turbo.\n",
        "-   `PyPDF2`: Helps with reading and working with PDF files.\n",
        "-   `chromadb`: A vector database used to store and search through embeddings.\n",
        "-   `tiktoken`: A fast tokenizer optimized for OpenAI’s models.\n",
        "-   `gradio`: Makes it easy to build user interfaces for ML applications.\n",
        "-   `langchain-community`: Adds community-supported integrations and tools for LangChain.\n",
        "-   `pypdf`: A pure Python library for splitting, merging, and modifying PDF files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6B7FtnaLIsnX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B7FtnaLIsnX",
        "outputId": "4894545c-26eb-48dd-e545-440c7ae8eae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.78)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.2)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install langchain openai PyPDF2 chromadb tiktoken gradio langchain-community pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "KBSBIMIGlc6R",
      "metadata": {
        "id": "KBSBIMIGlc6R"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader   # Loads PDF documents and extracts text\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # Splits large texts into smaller chunks for processing\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings # Converts text into vector embeddings using OpenAI models\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA             # Sets up a retrieval-based question-answering chain\n",
        "from langchain.chat_models import ChatOpenAI         # Uses OpenAI's chat models\n",
        "from langchain.prompts import PromptTemplate         # Helps format and customize prompts sent to the language model\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i2LXUb9_mMO8",
      "metadata": {
        "id": "i2LXUb9_mMO8"
      },
      "source": [
        "## OpenAI Client Initialization\n",
        "\n",
        "We initialize the OpenAI client with the API key. This key authenticates requests to OpenAI's servers. I have removed my API key before submitting in accordance with security best practices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yQFe7iG6oq0C",
      "metadata": {
        "id": "yQFe7iG6oq0C"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load OpenAI API key securely from environment variables\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "if not OPENAI_API_KEY:\n",
        "    raise ValueError(\"Missing OpenAI API Key. Please set the OPENAI_API_KEY environment variable.\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51j_SyTRgPZ1",
      "metadata": {
        "id": "51j_SyTRgPZ1"
      },
      "source": [
        "We will load the PDF document, splits it into smaller chunks, and creates a vector store using OpenAI embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "opyuf6mXo4Fa",
      "metadata": {
        "id": "opyuf6mXo4Fa"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load and process the PDF using PyPDFLoader\n",
        "loader = PyPDFLoader(\"/path/to/your/HR_policy_document.pdf\")\n",
        "documents = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "vwIFwuZFpMCE",
      "metadata": {
        "id": "vwIFwuZFpMCE"
      },
      "outputs": [],
      "source": [
        "# Splits text into manageable chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "sozbx3xhpn22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sozbx3xhpn22",
        "outputId": "608a70be-7c1e-4980-c17a-26e772561e3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2940743461.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embedding = OpenAIEmbeddings()\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Create embeddings and store in Chroma vector store\n",
        "\n",
        "# Initialize OpenAI embeddings\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "# Create a vector store from the text chunks\n",
        "vectorstore = Chroma.from_documents(texts, embedding, persist_directory=\"db\")\n",
        "\n",
        "# Create a retriever interface\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "SWFAf6mtpqGh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWFAf6mtpqGh",
        "outputId": "9d9e43c0-d58a-463a-b60a-eb3bd00b3898"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2352532703.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Define GPT-3.5 Turbo model and QA chain\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KdrQuJCZgZr_",
      "metadata": {
        "id": "KdrQuJCZgZr_"
      },
      "source": [
        "Let us look into what we will do next.\n",
        "\n",
        "- We’re going to create a custom prompt template to help the chatbot understand and respond to user queries.\n",
        "- The `RetrievalQA.from_chain_type` method will set up a question-answering chain using the GPT-3.5 Turbo model.\n",
        "- We’ll set the `chain_type` to \"stuff,\" so all the relevant documents get packed into the prompt.\n",
        "- The `retriever` will pull out the documents we need.\n",
        "- The `chain_type_kwargs` will let us pass in our custom prompt template to the chain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "Y9g_R6tVsz79",
      "metadata": {
        "id": "Y9g_R6tVsz79"
      },
      "outputs": [],
      "source": [
        "# Step 5: Define a custom prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=\"\"\"\n",
        "You are an AI assistant helping employees understand Nestlé's HR policies.\n",
        "Based on the following context, answer the question below:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\"prompt\": prompt_template}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "QEIudC_KxUWv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEIudC_KxUWv",
        "outputId": "1a905bd8-3260-491c-855e-f5eafd9f5f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gTTS) (2.32.5)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2ZwTdLvfxKML",
      "metadata": {
        "id": "2ZwTdLvfxKML"
      },
      "outputs": [],
      "source": [
        "from gtts import gTTS   # For text-to-speech\n",
        "import tempfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "22xHA3hE1mBu",
      "metadata": {
        "id": "22xHA3hE1mBu"
      },
      "outputs": [],
      "source": [
        "# --- Unified chatbot function for both text and voice --- #\n",
        "def chatbot_response(query):\n",
        "    # Run the QA chain\n",
        "    result = qa_chain.run(query)\n",
        "    # Generate speech output\n",
        "    tts = gTTS(result)\n",
        "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
        "    tts.save(temp_file.name)\n",
        "    return result, temp_file.name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "kqFHLLyM1ny1",
      "metadata": {
        "id": "kqFHLLyM1ny1"
      },
      "outputs": [],
      "source": [
        "# --- Build Gradio UI --- #\n",
        "with gr.Blocks(title=\"Nestlé HR Assistant Bot\") as demo:\n",
        "    gr.Markdown(\"## 🤖 Ask me about Nestlé's HR policies (via text or voice)\")\n",
        "\n",
        "    with gr.Tab(\"💬 Text Chat\"):\n",
        "        text_input = gr.Textbox(label=\"Enter your question\")\n",
        "        text_output = gr.Textbox(label=\"Answer (Text)\")\n",
        "        audio_output = gr.Audio(label=\"Answer (Voice)\")\n",
        "        text_button = gr.Button(\"Ask\")\n",
        "\n",
        "        text_button.click(fn=chatbot_response,\n",
        "                          inputs=text_input,\n",
        "                          outputs=[text_output, audio_output])\n",
        "\n",
        "    with gr.Tab(\"🎙️ Voice Chat\"):\n",
        "        mic_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak your question\")\n",
        "        voice_text_output = gr.Textbox(label=\"Answer (Text)\")\n",
        "        voice_audio_output = gr.Audio(label=\"Answer (Voice)\")\n",
        "\n",
        "        mic_input.change(fn=chatbot_response,\n",
        "                         inputs=mic_input,\n",
        "                         outputs=[voice_text_output, voice_audio_output])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "nO18AWbzxTmG",
      "metadata": {
        "id": "nO18AWbzxTmG"
      },
      "outputs": [],
      "source": [
        "# Gradio functions for text and voice\n",
        "\n",
        "def chatbot_interface(query):\n",
        "    result = qa_chain.run(query)\n",
        "    tts = gTTS(result)\n",
        "\n",
        "def chatbot_voice(audio):\n",
        "    # Convert speech to text automatically handled by Gradio Microphone input\n",
        "    # `audio` is a dict with keys \"name\", \"sample_rate\", \"data\"\n",
        "    # Gradio automatically does the transcription to text if using type=\"text\"\n",
        "    result = qa_chain.run(audio)\n",
        "    tts = gTTS(result)\n",
        "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
        "    tts.save(temp_file.name)\n",
        "    return result, temp_file.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "NuD10AvtySVN",
      "metadata": {
        "id": "NuD10AvtySVN"
      },
      "outputs": [],
      "source": [
        "# Gradio interface for text and voice\n",
        "\n",
        "with gr.Blocks(title=\"Nestlé HR Assistant Bot\") as demo:\n",
        "    gr.Markdown(\"## Ask me about Nestlé HR policies (text or voice)\")\n",
        "\n",
        "    with gr.Tab(\"Text Chat\"):\n",
        "        txt_in = gr.Textbox(label=\"Enter your question\")\n",
        "        txt_out = gr.Textbox(label=\"Answer\")\n",
        "        txt_btn = gr.Button(\"Ask\")\n",
        "        txt_btn.click(chatbot_interface, inputs=txt_in, outputs=txt_out)\n",
        "\n",
        "    with gr.Tab(\"Voice Chat\"):\n",
        "        mic_in = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak your question\")\n",
        "        voice_out_text = gr.Textbox(label=\"Answer (text)\")\n",
        "        voice_out_audio = gr.Audio(label=\"Answer (voice)\")\n",
        "        mic_in.change(chatbot_voice, inputs=mic_in, outputs=[voice_out_text, voice_out_audio])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "QRbPugxnz4aB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "QRbPugxnz4aB",
        "outputId": "1bcee95a-710b-4611-9b51-c5e8f32f0e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://abd4db7f4542545288.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://abd4db7f4542545288.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-jQdPfSrh5nh",
      "metadata": {
        "id": "-jQdPfSrh5nh"
      },
      "source": [
        "We will now create a Gradio interface for the chatbot. It takes the user's input (query), runs it through the QA chain, returns the result as output, and displays it in a simple interface where users can ask questions and get answers in real-time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ZpHqVcTs1L4",
      "metadata": {
        "id": "6ZpHqVcTs1L4"
      },
      "outputs": [],
      "source": [
        "# Step 6: Create a Gradio interface\n",
        "def chatbot_interface(query):\n",
        "    result = qa_chain.run(query)\n",
        "    return result\n",
        "\n",
        "gr.Interface(fn=chatbot_interface, inputs=\"text\", outputs=\"text\", title=\"Nestlé HR Assistant Bot\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "anr3534ziICz",
      "metadata": {
        "id": "anr3534ziICz"
      },
      "source": [
        "## Conclusion\n",
        "In this project, we built a chatbot that helps answer questions about Nestlé's HR policies. By using smart AI tools like OpenAI's GPT and Gradio for the interface, we created a simple, user-friendly way for employees to get quick answers straight from HR documents. This shows how AI can make HR work smoother and save everyone time by giving fast, accurate information when it is needed.\n",
        "\n",
        "### Future Scope and Improvements\n",
        "- **Expand Document Coverage:** The chatbot's knowledge base can be expanded by including more HR-related documents, such as training manuals, benefits information, and company-wide announcements.\n",
        "- **Improve Response Accuracy:** Fine-tuning the GPT model and refining the prompt template can lead to more accurate and relevant responses.\n",
        "- **Add Multi-Language Support:** Adding different language options would let employees from all over the world use it easily.\n",
        "- **Integrate with HR Systems:** This upgrade would make the chatbot even more powerful by providing personalized, real-time information. It would transform the bot into an essential tool for employees' day-to-day HR-related needs.\n",
        "- **Incorporate User Feedback:** Implement a system for collecting and incorporating user feedback to continuously improve the chatbot's performance and usability.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
